{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SphereFace Network\n",
    "[SphereFace: Deep Hypersphere Embedding for Face Recognition](http://wyliu.com/papers/LiuCVPR17v3.pdf)\n",
    "\n",
    "refered to [tensorflow sphereface](https://github.com/hujun100/tensorflow-sphereface)\n",
    "\n",
    "### Structure: four convolution units\n",
    "- Conv1.x\n",
    "- Conv2.x\n",
    "- Conv3.x\n",
    "- Conv4.x\n",
    "\n",
    "### Split the network into different parts\n",
    "- Conv with strides\n",
    "- Conv with residual units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caffe implementation\n",
    "Using the [Netscope](http://ethereon.github.io/netscope/#/editor) to show the caffe network defined in prototxt\n",
    "\n",
    "**Note**: Each Conv followed by a prelu layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/tf1.4_gpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/root/anaconda3/envs/tf1.4_gpu/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops #\n",
    "import numpy as np\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.prelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prelu(x, name = 'prelu'):\n",
    "    with tf.variable_scope(name):\n",
    "        alphas = tf.get_variable('alpha', x.get_shape()[-1], initializer=tf.constant_initializer(0.25), \n",
    "                                 regularizer = tf.contrib.layers.l2_regularizer(0.1), dtype = tf.float32)\n",
    "    pos = tf.nn.relu(x)\n",
    "    neg = tf.multiply(alphas,(x - abs(x)) * 0.5)\n",
    "    return pos + neg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.conv with strides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_conv(input, num_output, name):\n",
    "    with tf.variable_scope(name):\n",
    "        zero_init = tf.zeros_initializer()\n",
    "        l2_regularizer = tf.contrib.layers.l2_regularizer(0.1)\n",
    "        network = tf.layers.conv2d(input, num_output, kernel_size = [3, 3], strides = (2, 2), \n",
    "                                   padding = 'same', kernel_initializer = tf.contrib.layers.xavier_initializer(), \n",
    "                                   bias_initializer = zero_init, kernel_regularizer = l2_regularizer, \n",
    "                                   bias_regularizer = l2_regularizer)\n",
    "        network = prelu(network, name = name)\n",
    "        return network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.conv with residual units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def block(input, name, num_output):\n",
    "    with tf.variable_scope(name):\n",
    "        l2_regularizer = tf.contrib.layers.l2_regularizer(0.1)\n",
    "        network = tf.layers.conv2d(input, num_output, kernel_size = [3, 3], \n",
    "                                   strides = [1, 1], padding = 'same', \n",
    "                                   kernel_initializer = tf.random_normal_initializer(stddev=0.01), \n",
    "                                   use_bias = False , kernel_regularizer = l2_regularizer)\n",
    "        network = prelu(network, name = name+ '1')\n",
    "        network = tf.layers.conv2d(network, num_output, kernel_size = [3, 3], strides = [1, 1], \n",
    "                                   padding = 'same', kernel_initializer = tf.random_normal_initializer(stddev=0.01), \n",
    "                                   use_bias = False, kernel_regularizer = l2_regularizer)\n",
    "        network = prelu(network, name = name+ '2')\n",
    "        network = tf.add(input, network)\n",
    "        return network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_regularizer= tf.contrib.layers.l2_regularizer(1.0)\n",
    "xavier = tf.contrib.layers.xavier_initializer_conv2d() \n",
    "def get_shape(tensor):\n",
    "    static_shape = tensor.shape.as_list()\n",
    "    dynamic_shape = tf.unstack(tf.shape(tensor)) # 避免讀取到\"None\"的維度\n",
    "    dims = [s[1] if s[0] is None else s[0] for s in zip(static_shape,dynamic_shape)]\n",
    "    return dims\n",
    "def infer(input,embedding_size=512):\n",
    "    with tf.variable_scope('conv1_'):\n",
    "        network = first_conv(input, 64, name = 'conv1')\n",
    "        network = block(network, 'conv1_23', 64)\n",
    "    with tf.variable_scope('conv2_'):\n",
    "        network = first_conv(network, 128, name = 'conv2')\n",
    "        network = block(network, 'conv2_23', 128)\n",
    "        network = block(network, 'conv2_45', 128)\n",
    "    with tf.variable_scope('conv3_'):\n",
    "        network = first_conv(network, 256, name = 'conv3')\n",
    "        network = block(network, 'conv3_23', 256)\n",
    "        network = block(network, 'conv3_45', 256)\n",
    "        network = block(network, 'conv3_67', 256)\n",
    "        network = block(network, 'conv3_89', 256)\n",
    "    with tf.variable_scope('conv4_'):\n",
    "        network = first_conv(network, 512, name = 'conv4')\n",
    "        network = block(network, 'conv4_23', 512)\n",
    "    with tf.variable_scope('feature'):\n",
    "        #BATCH_SIZE = network.get_shape()[0]\n",
    "        dims = get_shape(network)\n",
    "        print(\"Before embedding: \", dims)\n",
    "        #BATCH_SIZE = tf.shape(network)[0]\n",
    "        #feature = tf.layers.dense(tf.reshape(network,[BATCH_SIZE, -1]), 512, kernel_regularizer = l2_regularizer, kernel_initializer = xavier)\n",
    "        feature = tf.layers.dense(tf.reshape(network,[dims[0], np.prod(dims[1:])]), embedding_size, kernel_regularizer = l2_regularizer, kernel_initializer = xavier)\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before embedding:  [1, 7, 6, 512]\n",
      "(1, 512)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.summary.writer.writer.FileWriter at 0x7fcc61251978>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "image = tf.random_normal([1,112,96,3])\n",
    "#image = tf.constant(np.random.normal(size=[1,112,96,3]),dtype=tf.float32)\n",
    "feature = infer(image)\n",
    "print(feature.get_shape())\n",
    "tf.summary.FileWriter('sphereface_network',tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1)\n"
     ]
    }
   ],
   "source": [
    "pred = tf.layers.dense(feature,1)\n",
    "print(pred.get_shape())\n",
    "loss = tf.nn.l2_loss(pred-1)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.0001).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.summary.writer.writer.FileWriter at 0x7fcc98844550>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.summary.FileWriter('sphereface_network_with_loss',tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49346137\n",
      "0.35183588\n",
      "0.2798277\n",
      "0.19106366\n",
      "0.12404491\n",
      "0.052884232\n",
      "0.025155758\n",
      "0.028904367\n",
      "0.017188251\n",
      "0.0040849955\n",
      "0.0066374065\n",
      "9.032418e-05\n",
      "0.0175079\n",
      "0.0001647973\n",
      "0.009843572\n",
      "8.311423e-05\n",
      "0.00060032046\n",
      "0.0015831499\n",
      "0.009624312\n",
      "0.0018905613\n",
      "0.007585963\n",
      "0.0019508458\n",
      "0.0029602624\n",
      "0.0030643062\n",
      "0.0017743644\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())# tf.Variable have to call variables_initializer() before nodes execution\n",
    "    for i in range(500): # iterations: 500\n",
    "        loss_np,_ = sess.run([loss,optimizer])\n",
    "        if i % 20 ==0: # display loss at each 20 iterations\n",
    "            print(loss_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.0046108]] 0.5046214\n",
      "[[0.17358987]] 0.34147683\n",
      "[[0.47952956]] 0.13544475\n",
      "[[0.5608841]] 0.09641138\n",
      "[[0.71087915]] 0.041795433\n",
      "[[0.709275]] 0.04226051\n",
      "[[0.94541484]] 0.0014897698\n",
      "[[0.84606004]] 0.011848756\n",
      "[[0.8744969]] 0.007875517\n",
      "[[0.8479135]] 0.011565152\n",
      "[[0.9592298]] 0.00083110353\n",
      "[[0.9769665]] 0.00026527105\n",
      "[[0.9334482]] 0.0022145712\n",
      "[[0.93308175]] 0.0022390264\n",
      "[[0.93302363]] 0.002242917\n",
      "[[0.88554215]] 0.006550299\n",
      "[[0.81490594]] 0.017129906\n",
      "[[0.95169616]] 0.0011666307\n",
      "[[1.0388279]] 0.0007538028\n",
      "[[0.9990282]] 4.721919e-07\n",
      "[[0.8782034]] 0.0074172067\n",
      "[[1.021663]] 0.00023464172\n",
      "[[0.98817146]] 6.99572e-05\n",
      "[[0.9784603]] 0.00023197908\n",
      "[[0.9187643]] 0.00329962\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())# tf.Variable have to call variables_initializer() before nodes execution\n",
    "    for i in range(500): # iterations: 500\n",
    "        pred_np, loss_np,_ = sess.run([pred, loss,optimizer])\n",
    "        if i % 20 ==0: # display loss at each 20 iterations\n",
    "            print(pred_np, loss_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
